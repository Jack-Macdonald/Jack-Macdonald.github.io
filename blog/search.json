[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nData Visualization Proposal\n\n\n\n\n\n\n\ndata visualization\n\n\nproposal\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment Three\n\n\n\n\n\n\n\ndata methods\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nData Methods Proposal\n\n\n\n\n\n\n\ndata methods\n\n\nproposal\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nHack-A-Thon\n\n\n\n\n\n\n\ndata visualization\n\n\nHack-A-Thon\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2023\n\n\nJack Macdonald, Veronica Kopper, Xiaoyan Zhang, Su Lin Goh\n\n\n\n\n\n\n  \n\n\n\n\nAssignment Three\n\n\n\n\n\n\n\ndata visualization\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nAssignment Two\n\n\n\n\n\n\n\ndata methods\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment Two\n\n\n\n\n\n\n\ndata visualization\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nAssignment One\n\n\n\n\n\n\n\ndata visualization\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nAssignment One\n\n\n\n\n\n\n\ndata methods\n\n\nassignment\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2023\n\n\nJack Macdonald\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Assignment One",
    "section": "",
    "text": "Q1)\nHere is the survey. It includes the changes from question three to six.\nQ2)\nA) The survey is comprised of a primer at the beginning followed by 17 questions.\nB) The questions ask the for opinions about at-home movie watching and some demographic questions at the end.\nC) There are blocks of three or four questions that relate to one another then it moves on to another related topic. For example, questions 4-6 all relate to proposed software that could detect possible not safe for work content. At the end, there are five questions about the individual.\nQ3-6) The changes to the survey were made in the published survey.\nQ7) Question two is not mobile friendly. The users cannot read the questions and all of the answer ranges at once. They must scroll left and right to find all of answer choices. This is also an issue of the questions with answer choices that are oriented horizontally."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a masters student at the University of Texas at Dallas studying data science and social data analytics.\nI graduated with a degree in Political Science from UTD in the fall of 2022 and continued working on my masters degree."
  },
  {
    "objectID": "posts/6356assignment1/index.html",
    "href": "posts/6356assignment1/index.html",
    "title": "Assignment One",
    "section": "",
    "text": "Q1) Anscombe\n\n\nShow Hidden Code\ndata(anscombe)\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] <- as.name(paste0(\"y\", i))\n  ##      ff[[3]] <- as.name(paste0(\"x\", i))\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  #print(anova(lmi))\n}\n\n# Preparing for the plots\nop <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\nQ2) Generative Art\nGenerative Art is created using an autonomous system with a set of parameters or boundaries. AI generated art has gained popularity with recent developments in consumer AI programs. Programs like Midjourney and OpenAI’s DALL-E are two examples. You can give a prompt to these programs and they will generate artwork based on it. This is not the only example of generative art. Hans Haacke used a form of generative art with Condensation Cube. The process of the condensation forming on the inside of the cube is the autonomous creation of this type of generative art. Generative art can also come in the form of music. Brian Eno is a musician that pioneered generative music. He created an album called “Generative Music 1” with the use of SSEYO’s Koan generative music system.\n\n\n\n\n\n\nNightCafe Art with the prompt “A Bob Ross painting in the style of Monet”\n\n\n\n\n\n\n\nCondensation Cube by Hans Haacke\n\n\n\n\n\n\n\nBrian Eno’s album Generative Music 1 (1996)\n\n\n\n\n\nQ3) Fall.R\n\n\nShow Hidden Code\nlibrary(gsubfn)\nlibrary(tidyverse)\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %>% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %>% rbind(points)->points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %>%\n      rbind(status) -> status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n\n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]->points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %>%\n      rbind(points) -> points\n    status[-1,]->status\n  }\n}\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"tomato3\", # Set your own Fall color?\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme(panel.background = element_rect(fill = \"wheat\"),\n        panel.grid = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        axis.text  = element_blank())\n\n\n\n\n\nQ4) Chart Critique\n\nThis is a chart that shows the location of popular pizza chains throughout the United States. While the graph does show a lot of data, it struggles with showing that data clearly. The points on the map are very small and that makes it difficult to interpret. The color palette does not help with interpretation either. A palette that has higher contrast color scheme may help, but with the points being so small, it would be difficult. Finally, while most people have a decent understanding of the size and scale of the United States, the map is missing a scale."
  },
  {
    "objectID": "posts/6302assignment2/index.html",
    "href": "posts/6302assignment2/index.html",
    "title": "Assignment Two",
    "section": "",
    "text": "Q2) Trends\n\n\n(If the graph does not show, click here to go to the site)\n\n\n\n\n\ngtrends.r\n\n\n\n\n\nlibrary(gtrendsR)\nBidenTrumpElection = gtrends(c(\"trump\",\"biden\",\"Election\"), time = \"now 7-d\")\npar(family=\"Georgia\")\nplot(BidenTrumpElection)\n\nWhen comparing the website data to the data collected in R, there is a difference between the number of hits collected by the two methods. The graphs look very similar because because the number of hits is very similar, just not quite the same. Both processes produce the data in the same way. When set to gather data over the span of a week, it collects the number of hits per hour for each search. That then can be used to create a plot showing the change over time. At time of writing this blog, the term “trump” has skyrocketed due to recent news and that can be seen in both graphs. (September 26th)\n\n\nClick here if Google Trends graph did not show\n\nHere are static photos of both the google trends website and library to show how similar they are. This will not be the most recent data (Sept. 19 - Sept. 26)"
  },
  {
    "objectID": "posts/6356assignment2/index.html",
    "href": "posts/6356assignment2/index.html",
    "title": "Assignment Two",
    "section": "",
    "text": "Q1) Rerun Murrell\n\n\nShow Code\npar(mfrow=c(3, 2))\n\nx <- c(0.5, 2, 4, 8, 12, 16)\ny1 <- c(1, 1.3, 1.9, 3.4, 3.9, 4.8)\ny2 <- c(4, .8, .5, .45, .4, .3)\n\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(x), c(0, 6))\nlines(x, y1)\nlines(x, y2)\npoints(x, y1, pch=16, cex=2) # Try different cex value?  \npoints(x, y2, pch=21, bg=\"white\", cex=2)  # Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(0, 16, 4)) # What is the first number standing for?\naxis(2, at=seq(0, 6, 2))\naxis(4, at=seq(0, 6, 2))\nbox(bty=\"u\")\nmtext(\"Travel Time (s)\", side=1, line=2, cex=0.8)\nmtext(\"Responses per Travel\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Responses per Second\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n# Histogram\n# Random data\nY <- rnorm(50)\n# Make sure no Y exceed [-3.5, 3.5]\nY[Y < -3.5 | Y > 3.5] <- NA # Selection/set range\nx <- seq(-3.5, 3.5, .1)\ndn <- dnorm(x)\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(Y, breaks=seq(-3.5, 3.5), ylim=c(0, 0.5), \n     col=\"gray80\", freq=FALSE)\nlines(x, dnorm(x), lwd=2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Barplot\npar(mar=c(2, 3.1, 2, 2.1)) \nmidpts <- barplot(VADeaths, \n                  col=gray(0.1 + seq(1, 9, 2)/11), \n                  names=rep(\"\", 4))\nmtext(sub(\" \", \"\\n\", colnames(VADeaths)),\n      at=midpts, side=1, line=0.5, cex=0.5)\ntext(rep(midpts, each=5), apply(VADeaths, 2, cumsum) - VADeaths/2,\n     VADeaths, \n     col=rep(c(\"white\", \"black\"), times=3:2), \n     cex=0.8)\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n# Boxplot\npar(mar=c(3, 4.1, 2, 0))\nboxplot(len ~ dose, data = ToothGrowth,\n        boxwex = 0.25, at = 1:3 - 0.2,\n        subset= supp == \"VC\", col=\"white\",\n        xlab=\"\",\n        ylab=\"tooth length\", ylim=c(0,35))\nmtext(\"Vitamin C dose (mg)\", side=1, line=2.5, cex=0.8)\nboxplot(len ~ dose, data = ToothGrowth, add = TRUE,\n        boxwex = 0.25, at = 1:3 + 0.2,\n        \n        subset= supp == \"OJ\")\nlegend(1.5, 9, c(\"Ascorbic acid\", \"Orange juice\"), \n       fill = c(\"white\", \"gray\"), \n       bty=\"n\")\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n# Persp\nx <- seq(-10, 10, length= 30)\ny <- x\nf <- function(x,y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }\nz <- outer(x, y, f)\nz[is.na(z)] <- 1\n# 0.5 to include z axis label\npar(mar=c(0, 0.5, 0, 0), lwd=0.5)\npersp(x, y, z, theta = 30, phi = 30, \n      expand = 0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales <- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)\nnames(pie.sales) <- c(\"Blueberry\", \"Cherry\",\n                      \"Apple\", \"Boston Cream\", \"Other\", \"Vanilla\")\npie(pie.sales, col = gray(seq(0.3,1.0,length=6)))"
  },
  {
    "objectID": "posts/6356assignment3/index.html",
    "href": "posts/6356assignment3/index.html",
    "title": "Assignment Three",
    "section": "",
    "text": "Q1) Anscombe Redux\n\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\n\n\nlm1 <- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\nlm2 <- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\nQ2) Fine Tuning\n\n\nShow Code\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nop <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0), family = \"Georgia\")\n\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"deeppink2\", pch = \"&\", bg = \"violetred2\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"maroon2\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\nQ3) ggplot\n\n\nShow Code\nlibrary(ggplot2)\nslope <- coef(lm1)[2]\nintercept <- coef(lm1)[1]\nggplot(anscombe, aes(x1,y1))+\n  geom_point(col=\"deeppink2\", size = 5, pch = \"&\")+\n  geom_abline(intercept = intercept, slope = slope, col = \"maroon2\")+\n  theme(text = element_text(family = \"Georgia\"))+\n  labs(title = \"Anscombe Model 1\")\n\n\n\n\n\nQ4) Pre-Hack-a-Thon\nIt is possible that the labels for the graph will not display properly, if so the output is shown in a drop down below.\n\n\nShow Code\nlibrary(ggplot2)\nowidata = read.csv(\"https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv?raw=true\")\nowidata = owidata[!grepl(\"^OWID\", owidata$iso_code), ]\nowideuro = subset(owidata, continent==\"Europe\")\n\nowideuro[is.na(owideuro)] <- 0\n\nowideuro$date <- as.Date(owideuro$date)\nsubset <- owideuro[c(20737,59890,59897,64552,32603,21472),]\n\nggplot(owideuro, aes(date, new_deaths))+\n  geom_point(col=\"deeppink2\", size=.75) +\n  geom_text(data = subset,\n            aes(label = location), \n            family = \"Georgia\",\n            vjust = -.75,\n            hjust = -.05)+\n  labs(x=\"Date\",y=\"COVID Deaths in Europe (Daily)\")+\n  theme(text = element_text(family = \"Georgia\"),\n        axis.text.x = element_text(angle = 90),\n        axis.text.y = element_text(angle = 90, hjust = .5),\n        axis.ticks.x = element_blank(),\n        panel.border = element_rect(fill = NA, color = \"black\", linewidth = 1),\n        panel.background = element_blank())+\n  scale_x_date(date_breaks = \"2 month\",\n               date_labels = \"%Y-%m\",\n               limits = c(as.Date(\"2020-02-03\"),max(owideuro$date))\n               )+\n  scale_y_continuous(breaks = seq(0,6000, by = 1000),\n                     labels = c(0,1000,\"\",3000,\"\",5000,\"\"))\n\n\n\n\n\n\n\nCorrect Graph"
  },
  {
    "objectID": "posts/6356assignment4/index.html",
    "href": "posts/6356assignment4/index.html",
    "title": "Hack-A-Thon",
    "section": "",
    "text": "Chart One - Variable Width Chart\nHere we created a graph using the “Iris” data set in R. There are three bars for each species that shows the average Pedal Length. The width is controlled by the average pedal width.\n\n\n\n\n\nChart Two - Table Embedded with Charts\nSticking with the Iris data, our table of charts is a scatterplot matrix of the correlations between each of the variables in the dataset, colored by each species.\n\n\n\n\n\nChart Three - Horizontal Bar Chart\nFor this we moved to the COVID data set that we used for a previous assignment. Here we showed the amount of new COVID cases in Germany over a duration of four years.\n\n\n\n\n\nChart Four - Overlapping Column Chart\nFinally for this chart we compared the amount of vaccinations per continent for each year. The color of the bars corresponds to each year and the height is the logarithm of the number of vaccinations for each continent."
  },
  {
    "objectID": "posts/Methods Proposal/index.html",
    "href": "posts/Methods Proposal/index.html",
    "title": "Data Methods Proposal",
    "section": "",
    "text": "Proposal Slides"
  },
  {
    "objectID": "posts/6302assignment3/index.html",
    "href": "posts/6302assignment3/index.html",
    "title": "Assignment Three",
    "section": "",
    "text": "Analyze) Biden-Xi Summit\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm <- dfm(toks)\n\n# Latent Semantic Analysis\nsum_lsa <- textmodel_lsa(sumtwtdfm)\n#summary(sum_lsa)\ntweet_dfm <- tokens(sum_twt, remove_punct = TRUE) %>%\n  dfm()\n#head(tweet_dfm)\ntag_dfm <- dfm_select(tweet_dfm, pattern = \"#*\")\ntoptag <- names(topfeatures(tag_dfm, 50))\n#head(toptag, 10)\n\ntag_fcm <- fcm(tag_dfm)\n#head(tag_fcm)\ntopgat_fcm <- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 5)\nuser_dfm <- dfm_select(tweet_dfm, pattern = \"@*\")\ntopuser <- names(topfeatures(user_dfm, 50))\n#head(topuser, 20)\nuser_fcm <- fcm(user_dfm)\n#head(user_fcm, 20)\n\nuser_fcm <- fcm_select(user_fcm, pattern = topuser)\ntextplot_network(user_fcm, min_freq = 20, edge_color = \"firebrick\", edge_alpha = 0.8, edge_size = 5)\n\n\n\n\n\n\n\n\n\nAnalyze) Speeches\n\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"american\") %>%\n  textplot_xray()\n\n\ntextplot_xray(\n  kwic(data_corpus_inaugural_subset, pattern = \"american\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"people\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"communist\")\n)"
  },
  {
    "objectID": "posts/Data Vis Proposal/index.html",
    "href": "posts/Data Vis Proposal/index.html",
    "title": "Data Visualization Proposal",
    "section": "",
    "text": "Proposal Slides\n\n\n\nMap Demo\n\n\n\n\nAttaching package: 'rmdexamples'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    kmeans_cluster\n\n\nPhantomJS not found. You can install it with webshot::install_phantomjs(). If it is installed, please make sure the phantomjs executable can be found via the PATH variable.\n\n\nShiny applications not supported in static R Markdown documents"
  }
]